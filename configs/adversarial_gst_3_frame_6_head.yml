sample_rate: 22050
hop_size: 256
f_min: 0
f_max: 8000
win_size: 1024
n_fft: 1024
n_mels: 80
checkpoint_name: tacotron_vctk_default_20_dur_3_frames_6_head_gst
hifi:
  dir_path: hifi
  model_name: generator_v1
  config_name: config.json
seed: 42
batch_size: 16
grad_clip_thresh: 1.0
log_steps: 1000
iters_per_checkpoint: 30000
epochs: 2500
test_size: 0.2
device: cuda:0
loss:
  mels_weight: 1.0
  duration_weight: 2.0
optimizer:
  learning_rate: 0.001
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-06
  reg_weight: 1e-06
scheduler:
  start_decay: 4000
  decay_steps: 50000
  decay_rate: 0.5
  last_epoch: 400000
data:
  text_dir: data/full/mfa_outputs
  mels_dir: data/full/mels
model:
  n_frames_per_step: 3
  encoder_config:
    n_convolutions: 3
    kernel_size: 5
    conv_channel: 512
    lstm_layers: 1
    lstm_hidden: 256
    dropout: 0.1
  gst_config:
    ref_enc_filters:
      - 32
      - 32
      - 64
      - 64
      - 128
      - 128
    emb_dim: 256
    num_heads: 8
    token_num: 10
  attention_config:
    duration_config:
      lstm_layers: 2
      lstm_hidden: 256
      dropout: 0.5
    range_config:
      lstm_layers: 2
      lstm_hidden: 256
      dropout: 0.5
    eps: 1e-6
    positional_dim: 32
    teacher_forcing_ratio: 1.0
    attention_dropout: 0.1
    positional_dropout: 0.0
  decoder_config:
    prenet_layers:
      - 256
      - 256
    prenet_dropout: 0.5
    decoder_rnn_dim: 512
    decoder_num_layers: 3
    teacher_forcing_ratio: 1.0
    dropout: 0.1
  postnet_config:
    embedding_dim: 512
    n_convolutions: 5
    kernel_size: 5
    dropout: 0.1
  mask_padding: true
  phonem_embedding_dim: 512
  speaker_embedding_dim: 256
