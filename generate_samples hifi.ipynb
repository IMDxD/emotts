{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f2a2f5-75b6-4f29-bfa3-687283fc3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import re\n",
    "from pathlib import Path\n",
    "from src.models.hifi_gan.models import Generator, load_model as load_hifi\n",
    "from src.train_config import TrainParams, load_config\n",
    "from src.preprocessing.text.cleaners import english_cleaners\n",
    "import subprocess\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadb30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"configs/esd_vctk_15.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f1d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79172a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(f\"checkpoints/{config.checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86155ddb-2ff2-4349-a647-e48e93dc7872",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = [file for file in (checkpoint_path / \"hifi\").rglob(\"*.*\") if file.name.startswith(\"g_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c22be1-9872-4fed-b351-d4565a89681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G2P_MODEL_PATH = \"models/en/g2p/english_g2p.zip\"\n",
    "G2P_OUTPUT_PATH = \"predictions/to_g2p.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311e7d39-cabf-43d5-8301-2600949b469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_file(user_query: str) -> None:\n",
    "    text_path = Path(\"tmp.txt\")\n",
    "    with open(text_path, \"w\") as fout:\n",
    "        normalized_content = english_cleaners(user_query)\n",
    "        normalized_content = \" \".join(re.findall(\"[a-zA-Z]+\", normalized_content))\n",
    "        fout.write(normalized_content)\n",
    "    subprocess.call(\n",
    "        [\"mfa\", \"g2p\", G2P_MODEL_PATH, text_path.absolute(), G2P_OUTPUT_PATH]\n",
    "    )\n",
    "    text_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ad11ab-3024-4935-b7d3-5301a319365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = {\"he\": \"HH IY1\", \"she\": \"SH IY1\", \"we\": \"W IY1\", \"be\": \"B IY0\", \"the\": \"DH AH0\", \"whenever\": \"W EH0 N EH1 V ER0\", \"year\": \"AH0 Y IH1 R\"}\n",
    "\n",
    "def parse_g2p(PHONEMES_TO_IDS, g2p_path: str = G2P_OUTPUT_PATH):\n",
    "    with open(g2p_path, \"r\") as fin:\n",
    "        phonemes_ids = []\n",
    "        phonemes = []\n",
    "        phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "        for line in fin:\n",
    "            word, word_to_phones = line.rstrip().split(\"\\t\", 1)\n",
    "            if word in default:\n",
    "                word_to_phones = default[word]\n",
    "            phonemes.extend(word_to_phones.split(\" \"))\n",
    "            phonemes_ids.extend(\n",
    "                [PHONEMES_TO_IDS[ph] for ph in word_to_phones.split(\" \")]\n",
    "            )\n",
    "        phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "    return phonemes_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21349f74-99be-44d0-bfd4-401ab32700c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Something must be done for them whenever they leave their current place and settle in a new home.\",\n",
    "    \"He then really thought himself equal to it.\",\n",
    "    \"I had felt that the best of life was over for me!\",\n",
    "    \"I hope a hundred pounds a year would make them all comfortable.\",\n",
    "    \"Perhaps it would have been as well if he had left it wholly to myself.\",\n",
    "    \"A pleasant renewing of old acquaintances, that was all I had thought it, not foreseeing that I was shortly to plunge into this whole situation.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "861fd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_phones = \"\"\"something\tS AH1 M TH IH0 NG\n",
    "must\tM AH1 S T\n",
    "be\tB IY1\n",
    "done\tD AH1 N\n",
    "for\tF AO1 R\n",
    "them\tDH AH0 M\n",
    "whenever\tW EH0 N EH1 V ER0\n",
    "they\tDH EY1\n",
    "leave\tL IY1 V\n",
    "their\tDH EH2 R\n",
    "current\tK ER1 AH0 N T\n",
    "place\tP L EY1 S\n",
    "and\tAE2 N D\n",
    "settle\tS EH1 T AH0 L\n",
    "in\tIH0 N\n",
    "a\tAH0\n",
    "new\tN UW1\n",
    "home\tHH OW1 M\n",
    "\n",
    "\n",
    "he\tHH IY1\n",
    "then\tDH EH1 N\n",
    "really\tR IY1 L IY0\n",
    "thought\tTH AO1 T\n",
    "himself\tHH IH0 M S EH1 L F\n",
    "equal\tIY1 K W AH0 L\n",
    "to\tT OW0\n",
    "it\tIH0 T\n",
    "\n",
    "\n",
    "i\tAY1\n",
    "had\tHH AE1 D\n",
    "felt\tF EH1 L T\n",
    "that\tDH AE1 T\n",
    "the\tDH AH0\n",
    "best\tB EH1 S T\n",
    "of\tAA1 F\n",
    "life\tL AY1 F\n",
    "was\tW AA1 Z\n",
    "over\tOW2 V ER0\n",
    "for\tF AO1 R\n",
    "me\tM IY1\n",
    "\n",
    "\n",
    "i\tAY1\n",
    "hope\tHH OW1 P\n",
    "a\tAH0\n",
    "hundred\tHH AH1 N D R IH0 D\n",
    "pounds\tP AW1 N D Z\n",
    "a\tAH0\n",
    "year\tY IH1 R\n",
    "would\tW UH1 D\n",
    "make\tM EY1 K\n",
    "them\tDH AH0 M\n",
    "all\tAH0 L\n",
    "comfortable\tK AH1 M F ER0 T AH0 B AH0 L\n",
    "\n",
    "\n",
    "perhaps\tP ER0 HH AE1 P S\n",
    "it\tIH0 T\n",
    "would\tW UH1 D\n",
    "have\tHH AE1 V\n",
    "been\tB IY0 N\n",
    "as\tAH0 S\n",
    "well\tW EH1 L\n",
    "if\tIH1 F\n",
    "he\tHH IY1\n",
    "had\tHH AE1 D\n",
    "left\tL EH1 F T\n",
    "it\tIH1 T\n",
    "wholly\tHH OW1 L IY0\n",
    "to\tT OW0\n",
    "myself\tM AY2 S EH1 L F\n",
    "\n",
    "\n",
    "a\tAH0\n",
    "pleasant\tP L EH1 Z AH0 N T\n",
    "renewing\tR IH0 N UW1 IH0 NG\n",
    "of\tAA1 F\n",
    "old\tOW1 L D\n",
    "acquaintances\tAH0 K W EY1 N T AH0 N S IH0 Z\n",
    "that\tDH AE1 T\n",
    "was\tW AA1 Z\n",
    "all\tAH0 L\n",
    "i\tAY1\n",
    "had\tHH AE1 D\n",
    "thought\tTH AO1 T\n",
    "it\tIH0 T\n",
    "not\tN AA1 T\n",
    "foreseeing\tF AO0 R S IY1 IH0 NG\n",
    "that\tDH AE1 T\n",
    "I\tAY1\n",
    "was\tW AA1 Z\n",
    "shortly\tSH AO1 R T L IY0\n",
    "to\tT OW0\n",
    "plunge\tP L AH1 N JH\n",
    "into\tIH0 N T AH0\n",
    "this\tDH IH0 S\n",
    "whole\tHH OW1 L\n",
    "situation\tS IH2 CH UW0 EY1 SH AH0 N\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e73ce066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_phones(PHONEMES_TO_IDS, phones):\n",
    "    phonemes_ids = []\n",
    "    phonemes = []\n",
    "    phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "    for line in phones.split(\"\\n\"):\n",
    "        if not line:\n",
    "            continue\n",
    "        word, word_to_phones = line.rstrip().split(\"\\t\", 1)\n",
    "        if word in default:\n",
    "            word_to_phones = default[word]\n",
    "        phonemes.extend(word_to_phones.split(\" \"))\n",
    "        phonemes_ids.extend(\n",
    "            [PHONEMES_TO_IDS[ph] for ph in word_to_phones.split(\" \")]\n",
    "        )\n",
    "    phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "    return phonemes_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7964ca84-3f26-4360-a1c7-6f5be890a25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phonemes_list = []\n",
    "with open(checkpoint_path / \"feature\"/ \"phonemes.json\") as f:\n",
    "    phonemes_to_ids = json.load(f)\n",
    "for hp in huawei_phones.split(\"\\n\\n\"):\n",
    "    phoneme_ids = to_phones(phonemes_to_ids, hp)\n",
    "    phonemes_list.append(phoneme_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fd31131",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = torch.load(checkpoint_path / \"feature\" / \"feature_model.pth\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "571cc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = feature_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4ee11d1-62eb-44ba-9ba5-5059cfc06d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tacotron_batch(\n",
    "    phonemes_ids, reference, speaker_id, device, mels_mean, mels_std\n",
    "):\n",
    "    text_lengths_tensor = torch.LongTensor([len(phonemes_ids)])\n",
    "    reference = (reference - mels_mean) / mels_std\n",
    "    reference = reference.permute(0, 2, 1).to(device)\n",
    "    phonemes_ids_tensor = torch.LongTensor(phonemes_ids).unsqueeze(0).to(device)\n",
    "    speaker_ids_tensor = torch.LongTensor([speaker_id]).to(device)\n",
    "    return phonemes_ids_tensor, text_lengths_tensor, speaker_ids_tensor, reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16bda806-58d1-4a20-8aac-2219004db025",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_pathes = Path(\"references/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f18e587-d1d0-4377-9a6b-d29de11c682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_path = Path(f\"generated_hifi/{config.checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aec1807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint_path / \"feature\"/ \"speakers.json\") as f:\n",
    "    speaker_to_id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2cb3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mels_mean = torch.load(checkpoint_path / \"feature\" / \"mels_mean.pth\").float()\n",
    "mels_std = torch.load(checkpoint_path / \"feature\" / \"mels_std.pth\").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "067cd832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a80e51b2374346b72c3875d6feaae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_hifi/esd_vctk_15/g_2515000/0014/neutral\n",
      "generated_hifi/esd_vctk_15/g_2515000/0014/neutral\n",
      "generated_hifi/esd_vctk_15/g_2515000/0014/neutral\n",
      "generated_hifi/esd_vctk_15/g_2515000/0014/neutral\n",
      "generated_hifi/esd_vctk_15/g_2515000/0014/neutral\n",
      "generated_hifi/esd_vctk_15/g_2515000/0014/neutral\n"
     ]
    }
   ],
   "source": [
    "for reference in tqdm(list(reference_pathes.rglob(\"*.pkl\"))):\n",
    "    speaker = reference.parent.name\n",
    "    speaker_id = speaker_to_id[speaker]\n",
    "    ref_mel = torch.load(reference)\n",
    "    for i, phonemes in enumerate(phonemes_list):\n",
    "        batch = get_tacotron_batch(phonemes, ref_mel, speaker_id, device, mels_mean, mels_std)\n",
    "        with torch.no_grad():\n",
    "            mels = feature_model.inference(batch)\n",
    "            mels = mels.permute(0, 2, 1).squeeze(0)\n",
    "            mels = mels * mels_std.to(device) + mels_mean.to(device)\n",
    "            x = mels.unsqueeze(0)\n",
    "        for generator_path in generators:\n",
    "            state_dict = torch.load(generator_path, map_location=device)\n",
    "            generator = Generator(config=config.train_hifi.model_param, num_mels=config.n_mels).to(device)\n",
    "            generator.load_state_dict(state_dict[\"generator\"])\n",
    "            generator.remove_weight_norm()\n",
    "            generator.eval()\n",
    "            y_g_hat = generator(x)\n",
    "            audio = y_g_hat.squeeze()\n",
    "            audio = audio * 32768\n",
    "            audio = audio.type(torch.int16).detach().cpu().numpy()\n",
    "            save_path = generated_path / generator_path.stem / speaker / reference.stem\n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            print(save_path)\n",
    "            wav_write(save_path / f\"{i + 1}.wav\", 22050, audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c4007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
