{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f2a2f5-75b6-4f29-bfa3-687283fc3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import re\n",
    "from pathlib import Path\n",
    "from src.models.hifi_gan.models import Generator, load_model as load_hifi\n",
    "from src.train_config import TrainParams, load_config\n",
    "from src.preprocessing.text.cleaners import english_cleaners\n",
    "import subprocess\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cadb30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"configs/esd_vctk_7_advloss0.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6f1d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e79172a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(f\"checkpoints/{config.checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86155ddb-2ff2-4349-a647-e48e93dc7872",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = [file for file in (checkpoint_path / \"hifi\").rglob(\"*.*\") if file.name.startswith(\"g_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87c22be1-9872-4fed-b351-d4565a89681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G2P_MODEL_PATH = \"models/en/g2p/english_g2p.zip\"\n",
    "G2P_OUTPUT_PATH = \"predictions/to_g2p.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "311e7d39-cabf-43d5-8301-2600949b469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_file(user_query: str) -> None:\n",
    "    text_path = Path(\"tmp.txt\")\n",
    "    with open(text_path, \"w\") as fout:\n",
    "        normalized_content = english_cleaners(user_query)\n",
    "        normalized_content = \" \".join(re.findall(\"[a-zA-Z]+\", normalized_content))\n",
    "        fout.write(normalized_content)\n",
    "    subprocess.call(\n",
    "        [\"mfa\", \"g2p\", G2P_MODEL_PATH, text_path.absolute(), G2P_OUTPUT_PATH]\n",
    "    )\n",
    "    text_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9ad11ab-3024-4935-b7d3-5301a319365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_g2p(PHONEMES_TO_IDS, g2p_path: str = G2P_OUTPUT_PATH):\n",
    "    with open(g2p_path, \"r\") as fin:\n",
    "        phonemes_ids = []\n",
    "        phonemes = []\n",
    "        for line in fin:\n",
    "            _, word_to_phones = line.rstrip().split(\"\\t\", 1)\n",
    "            phonemes.extend(word_to_phones.split(\" \"))\n",
    "            phonemes_ids.extend(\n",
    "                [PHONEMES_TO_IDS[ph] for ph in word_to_phones.split(\" \")]\n",
    "            )\n",
    "        phonemes_ids.append(PHONEMES_TO_IDS[\"<PAD>\"])\n",
    "    return phonemes_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21349f74-99be-44d0-bfd4-401ab32700c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Something must be done for them whenever they leave their current place and settle in a new home.\",\n",
    "    \"He then really thought himself equal to it.\",\n",
    "    \"I had felt that the best of life was over for me!\",\n",
    "    \"I hope a hundred pounds a year would make them all comfortable.\",\n",
    "    \"Perhaps it would have been as well if he had left it wholly to myself.\",\n",
    "    \"A pleasant renewing of old acquaintances, that was all I had thought it, not foreseeing that I was shortly to plunge into this whole situation.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7964ca84-3f26-4360-a1c7-6f5be890a25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phonemes_list = []\n",
    "with open(checkpoint_path / \"feature\"/ \"phonemes.json\") as f:\n",
    "    phonemes_to_ids = json.load(f)\n",
    "for t in texts:\n",
    "    text_to_file(t)\n",
    "    phoneme_ids = parse_g2p(phonemes_to_ids)\n",
    "    phonemes_list.append(phoneme_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fd31131",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = torch.load(checkpoint_path / \"feature\" / \"feature_model.pth\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "571cc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = feature_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4ee11d1-62eb-44ba-9ba5-5059cfc06d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tacotron_batch(\n",
    "    phonemes_ids, reference, speaker_id, device, mels_mean, mels_std\n",
    "):\n",
    "    text_lengths_tensor = torch.LongTensor([len(phonemes_ids)])\n",
    "    reference = (reference - mels_mean) / mels_std\n",
    "    reference = reference.permute(0, 2, 1).to(device)\n",
    "    phonemes_ids_tensor = torch.LongTensor(phonemes_ids).unsqueeze(0).to(device)\n",
    "    speaker_ids_tensor = torch.LongTensor([speaker_id]).to(device)\n",
    "    return phonemes_ids_tensor, text_lengths_tensor, speaker_ids_tensor, reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16bda806-58d1-4a20-8aac-2219004db025",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_pathes = Path(\"references/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f18e587-d1d0-4377-9a6b-d29de11c682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_path = Path(f\"generated_hifi/{config.checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aec1807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint_path / \"feature\"/ \"speakers.json\") as f:\n",
    "    speaker_to_id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2cb3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mels_mean = torch.load(checkpoint_path / \"feature\" / \"mels_mean.pth\").float()\n",
    "mels_std = torch.load(checkpoint_path / \"feature\" / \"mels_std.pth\").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "067cd832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c66fe5441143779a0b3144eb9414c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for reference in tqdm(list(reference_pathes.rglob(\"*.pkl\"))):\n",
    "    speaker = reference.parent.name\n",
    "    speaker_id = speaker_to_id[speaker]\n",
    "    ref_mel = torch.load(reference)\n",
    "    for i, phonemes in enumerate(phonemes_list):\n",
    "        batch = get_tacotron_batch(phonemes, ref_mel, speaker_id, device, mels_mean, mels_std)\n",
    "        with torch.no_grad():\n",
    "            mels = feature_model.inference(batch)\n",
    "            mels = mels.permute(0, 2, 1).squeeze(0)\n",
    "            mels = mels * mels_std.to(device) + mels_mean.to(device)\n",
    "            x = mels.unsqueeze(0)\n",
    "        for generator_path in generators:\n",
    "            state_dict = torch.load(generator_path, map_location=device)\n",
    "            generator = Generator(config=config.train_hifi.model_param, num_mels=config.n_mels).to(device)\n",
    "            generator.load_state_dict(state_dict[\"generator\"])\n",
    "            generator.remove_weight_norm()\n",
    "            generator.eval()\n",
    "            y_g_hat = generator(x)\n",
    "            audio = y_g_hat.squeeze()\n",
    "            audio = audio * 32768\n",
    "            audio = audio.type(torch.int16).detach().cpu().numpy()\n",
    "            save_path = generated_path / generator_path.stem / speaker / reference.stem\n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            wav_write(save_path / f\"{i + 1}.wav\", 22050, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c4007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
