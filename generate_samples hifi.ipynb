{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f2a2f5-75b6-4f29-bfa3-687283fc3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import re\n",
    "from pathlib import Path\n",
    "from src.models.hifi_gan.models import Generator, load_model as load_hifi\n",
    "from src.train_config import TrainParams, load_config\n",
    "from src.preprocessing.text.cleaners import english_cleaners\n",
    "import subprocess\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadb30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"configs/esd_vctk_15.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f1d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79172a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(f\"checkpoints/{config.checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86155ddb-2ff2-4349-a647-e48e93dc7872",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = [file for file in (checkpoint_path / \"hifi\").rglob(\"*.*\") if file.name.startswith(\"g_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c22be1-9872-4fed-b351-d4565a89681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G2P_MODEL_PATH = \"models/en/g2p/english_g2p.zip\"\n",
    "G2P_OUTPUT_PATH = \"predictions/to_g2p.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311e7d39-cabf-43d5-8301-2600949b469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_file(user_query: str) -> None:\n",
    "    text_path = Path(\"tmp.txt\")\n",
    "    with open(text_path, \"w\") as fout:\n",
    "        normalized_content = english_cleaners(user_query)\n",
    "        normalized_content = \" \".join(re.findall(\"[a-zA-Z]+\", normalized_content))\n",
    "        fout.write(normalized_content)\n",
    "    subprocess.call(\n",
    "        [\"mfa\", \"g2p\", G2P_MODEL_PATH, text_path.absolute(), G2P_OUTPUT_PATH]\n",
    "    )\n",
    "    text_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ad11ab-3024-4935-b7d3-5301a319365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = {\"he\": \"HH IY1\", \"she\": \"SH IY1\", \"we\": \"W IY1\", \"be\": \"B IY0\", \"the\": \"DH AH0\", \"whenever\": \"W EH0 N EH1 V ER0\", \"year\": \"AH0 Y IH1 R\"}\n",
    "\n",
    "def parse_g2p(PHONEMES_TO_IDS, g2p_path: str = G2P_OUTPUT_PATH):\n",
    "    with open(g2p_path, \"r\") as fin:\n",
    "        phonemes_ids = []\n",
    "        phonemes = []\n",
    "        phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "        for line in fin:\n",
    "            word, word_to_phones = line.rstrip().split(\"\\t\", 1)\n",
    "            if word in default:\n",
    "                word_to_phones = default[word]\n",
    "            phonemes.extend(word_to_phones.split(\" \"))\n",
    "            phonemes_ids.extend(\n",
    "                [PHONEMES_TO_IDS[ph] for ph in word_to_phones.split(\" \")]\n",
    "            )\n",
    "        phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "    return phonemes_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21349f74-99be-44d0-bfd4-401ab32700c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Something must be done for them whenever they leave their current place and settle in a new home.\",\n",
    "    \"He then really thought himself equal to it.\",\n",
    "    \"I had felt that the best of life was over for me!\",\n",
    "    \"I hope a hundred pounds a year would make them all comfortable.\",\n",
    "    \"Perhaps it would have been as well if he had left it wholly to myself.\",\n",
    "    \"A pleasant renewing of old acquaintances, that was all I had thought it, not foreseeing that I was shortly to plunge into this whole situation.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "861fd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "huawei_phones = \"\"\"S AH1 M TH IH0 NG\n",
    "M AH1 S T\n",
    "B IY1\n",
    "D AH1 N\n",
    "F AO1 R\n",
    "DH EH1 M\n",
    "W EH0 N EH1 V ER0\n",
    "DH EY1\n",
    "L IY1 V\n",
    "DH EH1 R\n",
    "K ER1 AH0 N T\n",
    "P L EY1 S\n",
    "AH0 N D\n",
    "S EH1 T AH0 L\n",
    "IH0 N\n",
    "AH0\n",
    "N UW1\n",
    "HH OW1 M\n",
    "\n",
    "\n",
    "HH IY1\n",
    "DH EH1 N\n",
    "R IH1 L IY0\n",
    "TH AO1 T\n",
    "HH IH0 M S EH1 L F\n",
    "IY1 K W AH0 L\n",
    "T UW1\n",
    "IH1 T\n",
    "\n",
    "\n",
    "AY1\n",
    "HH AE1 D\n",
    "F EH1 L T\n",
    "DH AE1 T\n",
    "DH AH0\n",
    "B EH1 S T\n",
    "AH1 V\n",
    "L AY1 F\n",
    "W AA1 Z\n",
    "OW1 V ER0\n",
    "F AO1 R\n",
    "M IY1\n",
    "\n",
    "\n",
    "AY1\n",
    "HH OW1 P\n",
    "AH0\n",
    "HH AH1 N D R AH0 D\n",
    "P AW1 N D Z\n",
    "AH0\n",
    "Y IH1 R\n",
    "W UH1 D\n",
    "M EY1 K\n",
    "DH EH1 M\n",
    "AO1 L\n",
    "K AH1 M F ER0 T AH0 B AH0 L\n",
    "\n",
    "\n",
    "P ER0 HH AE1 P S\n",
    "IH1 T\n",
    "W UH1 D\n",
    "HH AE1 V\n",
    "B IH1 N\n",
    "AE1 Z\n",
    "W EH1 L\n",
    "IH1 F\n",
    "HH IY1\n",
    "HH AE1 D\n",
    "L EH1 F T\n",
    "IH1 T\n",
    "HH OW1 L IY0\n",
    "T UW0\n",
    "M AY2 S EH1 L F\n",
    "\n",
    "\n",
    "AH0\n",
    "P L EH1 Z AH0 N T\n",
    "R IH0 N UW1 IH0 NG\n",
    "AH1 V\n",
    "OW1 L D\n",
    "AH0 K W EY1 N T AH0 N S IH0 Z\n",
    " \n",
    "DH AE1 T\n",
    "W AA1 Z\n",
    "AO1 L\n",
    "AY1\n",
    "HH AE1 D\n",
    "TH AO1 T\n",
    "IH1 T\n",
    " \n",
    "N AA1 T\n",
    "F AO0 R S IY1 IH0 NG\n",
    "DH AE1 T\n",
    "AY1\n",
    "W AA1 Z\n",
    "SH AO1 R T L IY0\n",
    "T UW0\n",
    "P L AH1 N JH\n",
    "IH1 N T UW0\n",
    "DH IH1 S\n",
    "HH OW1 L\n",
    "S IH2 CH UW0 EY1 SH AH0 N\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e73ce066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_phones(PHONEMES_TO_IDS, phones):\n",
    "    phonemes_ids = []\n",
    "    phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "    for line in phones.split(\"\\n\"):\n",
    "        if not line:\n",
    "            continue\n",
    "        word_to_phones = line\n",
    "        phonemes_ids.extend(\n",
    "            [PHONEMES_TO_IDS[ph] for ph in word_to_phones.split(\" \")]\n",
    "        )\n",
    "    phonemes_ids.append(PHONEMES_TO_IDS[\"\"])\n",
    "    return phonemes_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7964ca84-3f26-4360-a1c7-6f5be890a25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phonemes_list = []\n",
    "with open(checkpoint_path / \"feature\"/ \"phonemes.json\") as f:\n",
    "    phonemes_to_ids = json.load(f)\n",
    "for hp in huawei_phones.split(\"\\n\\n\\n\"):\n",
    "    phoneme_ids = to_phones(phonemes_to_ids, hp)\n",
    "    phonemes_list.append(phoneme_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8fd31131",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = torch.load(checkpoint_path / \"feature\" / \"feature_model.pth\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "571cc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = feature_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4ee11d1-62eb-44ba-9ba5-5059cfc06d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tacotron_batch(\n",
    "    phonemes_ids, reference, speaker_id, device, mels_mean, mels_std\n",
    "):\n",
    "    text_lengths_tensor = torch.LongTensor([len(phonemes_ids)])\n",
    "    reference = (reference - mels_mean) / mels_std\n",
    "    reference = reference.permute(0, 2, 1).to(device)\n",
    "    phonemes_ids_tensor = torch.LongTensor(phonemes_ids).unsqueeze(0).to(device)\n",
    "    speaker_ids_tensor = torch.LongTensor([speaker_id]).to(device)\n",
    "    return phonemes_ids_tensor, text_lengths_tensor, speaker_ids_tensor, reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16bda806-58d1-4a20-8aac-2219004db025",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_pathes = Path(\"references/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0f18e587-d1d0-4377-9a6b-d29de11c682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_path = Path(f\"generated_hifi/{config.checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aec1807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint_path / \"feature\"/ \"speakers.json\") as f:\n",
    "    speaker_to_id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e2cb3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mels_mean = torch.load(checkpoint_path / \"feature\" / \"mels_mean.pth\").float()\n",
    "mels_std = torch.load(checkpoint_path / \"feature\" / \"mels_std.pth\").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "067cd832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd1f037e9254b93955ac7c0e0bd541b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for reference in tqdm(list(reference_pathes.rglob(\"*.pkl\"))[0:1]):\n",
    "    speaker = reference.parent.name\n",
    "    speaker_id = speaker_to_id[speaker]\n",
    "    ref_mel = torch.load(reference)\n",
    "    for i, phonemes in enumerate(phonemes_list[4:]):\n",
    "        batch = get_tacotron_batch(phonemes, ref_mel, speaker_id, device, mels_mean, mels_std)\n",
    "        with torch.no_grad():\n",
    "            mels = feature_model.inference(batch)\n",
    "            mels = mels.permute(0, 2, 1).squeeze(0)\n",
    "            mels = mels * mels_std.to(device) + mels_mean.to(device)\n",
    "            x = mels.unsqueeze(0)\n",
    "        for generator_path in generators[0:1]:\n",
    "            state_dict = torch.load(generator_path, map_location=device)\n",
    "            generator = Generator(config=config.train_hifi.model_param, num_mels=config.n_mels).to(device)\n",
    "            generator.load_state_dict(state_dict[\"generator\"])\n",
    "            generator.remove_weight_norm()\n",
    "            generator.eval()\n",
    "            y_g_hat = generator(x)\n",
    "            audio = y_g_hat.squeeze()\n",
    "            audio = audio * 32768\n",
    "            audio = audio.type(torch.int16).detach().cpu().numpy()\n",
    "            save_path = generated_path / generator_path.stem / speaker / reference.stem\n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            wav_write(save_path / f\"{i + 1}.wav\", 22050, audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c4007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
