{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from librosa.filters import mel as librosa_mel\n",
    "\n",
    "# Using the same parameters as in HiFiGAN\n",
    "F_MIN = 0\n",
    "F_MAX = 8000\n",
    "HOP_SIZE = 256\n",
    "WIN_SIZE = 1024\n",
    "N_FFT = 1024\n",
    "N_MELS = 80\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "\n",
    "def spectral_normalize_torch(magnitudes: torch.Tensor) -> torch.Tensor:\n",
    "    output = torch.log(torch.clamp(magnitudes, min=1e-5))\n",
    "    return output\n",
    "\n",
    "\n",
    "def mel_spectrogram(y: torch.Tensor,\n",
    "                    n_fft: int = N_FFT, num_mels: int = N_MELS,\n",
    "                    sample_rate: int= SAMPLE_RATE, hop_size: int = HOP_SIZE,\n",
    "                    win_size: int = WIN_SIZE, fmin: int = F_MIN, fmax: int = F_MAX,\n",
    "                    center: bool = False) -> torch.Tensor:\n",
    "\n",
    "    hann_window, mel_basis = {}, {}\n",
    "\n",
    "    if fmax not in mel_basis:\n",
    "        mel = librosa_mel(sample_rate, n_fft, num_mels, fmin, fmax)\n",
    "        mel_basis[f\"{fmax}_{y.device}\"] = torch.from_numpy(mel).float().to(y.device)\n",
    "        hann_window[f\"{y.device}\"] = torch.hann_window(win_size).to(y.device)\n",
    "\n",
    "    y = torch.nn.functional.pad(y.unsqueeze(1),\n",
    "                                (int((n_fft - hop_size) / 2), int((n_fft - hop_size) / 2)),\n",
    "                                mode='reflect')\n",
    "    print(y.shape)\n",
    "\n",
    "    spec = torch.stft(y.squeeze(1), n_fft, hop_length=hop_size,\n",
    "                      win_length=win_size, window=hann_window[str(y.device)],\n",
    "                      center=center, pad_mode='reflect',\n",
    "                      normalized=False, onesided=True)\n",
    "    print(spec.shape)\n",
    "\n",
    "    spec = torch.sqrt(spec.pow(2).sum(-1) + 1e-9)\n",
    "    spec = torch.matmul(mel_basis[f\"{fmax}_{y.device}\"], spec)\n",
    "    spec = spectral_normalize_torch(spec)\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64543])\n",
      "torch.Size([1, 1, 65311])\n",
      "torch.Size([1, 513, 252, 2])\n",
      "torch.Size([1, 80, 252])\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"../data/processed/mfa_inputs\"\n",
    "\n",
    "path = Path(input_dir)\n",
    "\n",
    "filepath_list = list(path.rglob('*.flac'))\n",
    "\n",
    "for file in filepath_list:\n",
    "    wave_tensor, _ = torchaudio.load(file)\n",
    "\n",
    "    print(wave_tensor.shape)\n",
    "    mels_tensor = mel_spectrogram(wave_tensor, center=False)  # [n_channels x n_mels x time]\n",
    "    print(mels_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64512\n",
      "64768\n"
     ]
    }
   ],
   "source": [
    "print(256 * 252)\n",
    "print(256 * 253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 253])\n"
     ]
    }
   ],
   "source": [
    "from torchaudio.transforms import MelSpectrogram\n",
    "\n",
    "\n",
    "HOP_SIZE = 256\n",
    "N_FFT = 1024\n",
    "N_MELS = 80  # required by HiFi-GAN\n",
    "NORMALIZED = False\n",
    "SAMPLE_RATE = 22050\n",
    "WIN_SIZE = 1024\n",
    "\n",
    "transformer = MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=N_FFT,\n",
    "    win_length=WIN_SIZE,\n",
    "    hop_length=HOP_SIZE,\n",
    "    f_min=F_MIN,\n",
    "    f_max=F_MAX,\n",
    "    n_mels=N_MELS,\n",
    "    normalized=NORMALIZED,\n",
    "    # norm = 'slaney',\n",
    ")\n",
    "\n",
    "new_tensor = transformer(wave_tensor)\n",
    "print(new_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a080aa9d1b7381953f30d28909ae984f6fab7702369768ce42dba48e871a3e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('emotts': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
