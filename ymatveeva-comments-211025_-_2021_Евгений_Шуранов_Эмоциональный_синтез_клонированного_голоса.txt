
слайд  2 "Критерии оценки":
   -- на мой взгляд критерии из шаблона больше заточены на алгоритмические задачи, чем на задачи машинного обучения (когда результат один, фиксированный и детерминированный, и сложность лишь в том, чтобы его побыстрее и поэффективнее достичь).
   Я бы добавила в пункт 1: качество работы финальной модели, оцениваемое через стандартные метрики для выбранной области (для синтеза речи: MOS на естественность речи и отсутствие в ней артефактов, точность контроля за прозодией речи,   similarity на похожесть синтезируемого голоса на оригинал по тембру (везде выше 2.5)). В пункт 3: за дополнительное усложнение поставленной задачи (клонирование вместо синтеза), повышенную сложность используемых технологий (обучение энкодера референс аудио), достижение особо высоких метрик оценки финальной модели (MOS на естественность речи, точность контроля за прозодией речи).

 Слайды 4 и 5: узковатый взгляд. Чат-ботами все не ограничивается. Смотрите мой слайд, присылаю в чат.
 
 Слайд 5: неверный, хотя бы исходя из ссылок на демки, которые должны были остаться в моем обзоре статей по ЭМО, который мы вым высылали по почте. Но там про академические решения. В плане бизнес-решений можете погуглить IBM, Microsoft, Amazon Polly. На TTS API. Каждый предлагает модификацию интонаций либо по эмоциям, либо по стилю речи в более абстрактном понимании. Но последнее пока что превалирует. Однако технологии для первого и второго (как видно из обзора статей) используются аналогичные. Проблема в том, что по стилям речи данные проще собирать, чем по узко-определенным эмоциям.
 
 Интеграция в существующие сервисы: надо ли добавить нерусскоязычны решения (английский) ? 
